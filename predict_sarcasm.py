# -*- coding: utf-8 -*-
"""predict_sarcasm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XmKd6DDRuKjWhxUsJj3TpDRUMyGp9MjC
"""

import tensorflow as tf
import pickle
from tensorflow.keras.preprocessing.sequence import pad_sequences
import re

# Load the trained model
MODEL_PATH = "/content/lstm_sarcasm_model.h5"  # Change to .h5 if needed
model = tf.keras.models.load_model(MODEL_PATH)

# Load the tokenizer
with open("tokenizer.pkl", "rb") as handle:
    tokenizer = pickle.load(handle)

# Function to clean and preprocess input text
def clean_text(text):
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", "", text, flags=re.MULTILINE)  # Remove URLs
    text = re.sub(r'\@\w+|\#', "", text)  # Remove mentions and hashtags
    text = re.sub(r'[^\w\s]', "", text)  # Remove punctuation
    return text

def preprocess_text(text):
    text = clean_text(text)
    sequence = tokenizer.texts_to_sequences([text])
    padded_sequence = pad_sequences(sequence, maxlen=50, padding='post', truncating='post')
    return padded_sequence

# Function to predict sarcasm
def predict_sarcasm(text):
    processed_text = preprocess_text(text)
    prediction = model.predict(processed_text)[0][0]
    return "Sarcastic 😏" if prediction > 0.5 else "Not Sarcastic 😊"

# Example usage (for testing)
if __name__ == "__main__":
    while True:
        user_input = input("Enter a sentence (or type 'exit' to quit): ")
        if user_input.lower() == "exit":
            break
        print(f"Prediction: {predict_sarcasm(user_input)}")